{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.10.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from pygame import mixer \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detect = mp.solutions.face_detection\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh ( \n",
    "    max_num_faces=1,\n",
    "    static_image_mode=False,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "face_detect = mp_face_detect.FaceDetection (\n",
    "    min_detection_confidence=0.6\n",
    ")\n",
    "\n",
    "video_src = 0\n",
    "eye_classes = {0: 'closed', 1: 'opened'}\n",
    "face_classes = {0: 'no_yawned', 1: 'yawned'}\n",
    "eye_class_colors = {'closed': (0, 0, 255), 'opened': (0, 255, 0)}\n",
    "face_class_colors = {'no_yawned': (255, 0, 0), 'yawned': (0, 255, 255)}\n",
    "sleep_counter = 0\n",
    "sleep_counter_thresh = 8\n",
    "sleep_attempts = 0\n",
    "yawn_attempts = 0\n",
    "prev_yawn_pred_class = None\n",
    "sleep_mood_alert_countdown_thresh = 8\n",
    "sleep_mood_alert_countdown = None\n",
    "alert_sound_path = '../media/Pure Alert Sound.wav'\n",
    "alert_sound_len = 2\n",
    "last_alert_played_at = None \n",
    "\n",
    "mixer.init()\n",
    "mixer.music.load(alert_sound_path)\n",
    "mixer.music.set_volume(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_model = Sequential()\n",
    "\n",
    "eye_model.add(Conv2D(128, (5, 5), input_shape=(48, 48, 1), activation='relu'))\n",
    "eye_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "eye_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "eye_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "eye_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "eye_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "eye_model.add(Flatten())\n",
    "\n",
    "eye_model.add(Dense(256, activation='relu'))\n",
    "eye_model.add(Dense(64, activation='relu'))\n",
    "eye_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "eye_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "eye_model.load_weights('../models/sleep_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yawn_model = Sequential()\n",
    "\n",
    "yawn_model.add(Conv2D(128, (3, 3), input_shape=(48, 48, 1), activation='relu'))\n",
    "yawn_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "yawn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "yawn_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "yawn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "yawn_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "yawn_model.add(Flatten())\n",
    "\n",
    "yawn_model.add(Dense(128, activation='relu'))\n",
    "yawn_model.add(Dense(32, activation='relu'))\n",
    "yawn_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "yawn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "yawn_model.load_weights('../models/yawn_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model=eye_model, res=(48, 48), image=None, classes=eye_classes):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (res[0], res[1]))\n",
    "    image = image / 255.0\n",
    "    image = np.reshape(image, (1, image.shape[0], image.shape[1], 1))\n",
    "    prediction = model.predict(image)\n",
    "    pred_argmax = np.argmax(prediction, axis=1)[0]\n",
    "    \n",
    "    return classes[pred_argmax], int(prediction[0][pred_argmax] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True: \n",
    "    ret, frame = cam.read()\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    if ret:\n",
    "        face_detect_results = face_mesh_results = None\n",
    "        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_detect_results = face_detect.process(rgb_image)\n",
    "        face_mesh_results = face_mesh.process(rgb_image)\n",
    "        \n",
    "        if face_detect_results.detections:\n",
    "            for face in face_detect_results.detections:\n",
    "                rel_bound_rect = face.location_data.relative_bounding_box\n",
    "                face_x, face_w, face_y, face_h = int(rel_bound_rect.xmin * width), int(rel_bound_rect.width * width), int(rel_bound_rect.ymin * height), int(rel_bound_rect.height * height)\n",
    "                face = frame[face_y: face_y + face_h, face_x: face_x + face_w]\n",
    "                yawn_pred_class, yawn_pred_acc = predict(model=yawn_model, image=face, classes=face_classes)\n",
    "                \n",
    "                prev_yawn_attempts = yawn_attempts\n",
    "                if yawn_pred_class == 'yawned' and prev_yawn_pred_class != yawn_pred_class:\n",
    "                    yawn_attempts += 1\n",
    "                prev_yawn_pred_class = yawn_pred_class\n",
    "                    \n",
    "        \n",
    "        if face_mesh_results.multi_face_landmarks:\n",
    "            init_landmarks = {55: None, 117: None, 285: None}\n",
    "            for face_landmarks in face_mesh_results.multi_face_landmarks:\n",
    "                for i, landmark in enumerate(face_landmarks.landmark):\n",
    "                    if i in init_landmarks:\n",
    "                        lm_x, lm_y = int(landmark.x * width), int(landmark.y * height)\n",
    "                        init_landmarks[i] = lm_x, lm_y\n",
    "\n",
    "            left_eye_bound_rect = (init_landmarks[117][0], init_landmarks[55][1]), (init_landmarks[55][0], init_landmarks[117][1])\n",
    "            right_eye_bound_rect = (init_landmarks[285][0], init_landmarks[285][1]), (init_landmarks[285][0] + (left_eye_bound_rect[1][0] - left_eye_bound_rect[0][0]), init_landmarks[117][1])\n",
    "            left_eye_bound_rect_h, left_eye_bound_rect_w = left_eye_bound_rect[1][1] - left_eye_bound_rect[0][1], left_eye_bound_rect[1][0] - left_eye_bound_rect[0][0]\n",
    "            right_eye_bound_rect_h, right_eye_bound_rect_w = right_eye_bound_rect[1][1] - right_eye_bound_rect[0][1], right_eye_bound_rect[1][0] - right_eye_bound_rect[0][0]\n",
    "            left_eye = frame[left_eye_bound_rect[0][1]: left_eye_bound_rect[0][1] + left_eye_bound_rect_h, left_eye_bound_rect[0][0]: left_eye_bound_rect[0][0] + left_eye_bound_rect_w]\n",
    "            right_eye = frame[right_eye_bound_rect[0][1]: right_eye_bound_rect[0][1] + right_eye_bound_rect_h, right_eye_bound_rect[0][0]: right_eye_bound_rect[0][0] + right_eye_bound_rect_w]\n",
    "            left_eye_pred_class, left_eye_pred_acc = predict(image=left_eye)\n",
    "            right_eye_pred_class, right_eye_pred_acc = predict(image=right_eye)\n",
    "            \n",
    "            if left_eye_pred_class == right_eye_pred_class == 'closed':\n",
    "                sleep_counter += 1\n",
    "            else:\n",
    "                sleep_counter = 0\n",
    "            \n",
    "        if face_detect_results.detections:\n",
    "            cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), face_class_colors[yawn_pred_class], 2)\n",
    "        if face_mesh_results.multi_face_landmarks:    \n",
    "            cv2.rectangle(frame, (left_eye_bound_rect[0][0], left_eye_bound_rect[0][1]), (left_eye_bound_rect[1][0], left_eye_bound_rect[1][1]), eye_class_colors[left_eye_pred_class], 2)\n",
    "            cv2.rectangle(frame, (right_eye_bound_rect[0][0], right_eye_bound_rect[0][1]), (right_eye_bound_rect[1][0], right_eye_bound_rect[1][1]), eye_class_colors[right_eye_pred_class], 2)\n",
    "            cv2.putText(frame, 'Face:', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (45, 255, 45), 2)\n",
    "            cv2.putText(frame, f'{yawn_pred_class.title()} ({yawn_pred_acc}%)', (70, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.55, face_class_colors[yawn_pred_class], 2)\n",
    "            cv2.putText(frame, 'L.Eye:', (15, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (45, 255, 45), 2)\n",
    "            cv2.putText(frame, f'{left_eye_pred_class.title()} ({left_eye_pred_acc}%)', (70, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.55, eye_class_colors[left_eye_pred_class], 2)\n",
    "            cv2.putText(frame, 'R.Eye:', (15, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (45, 255, 45), 2)\n",
    "            cv2.putText(frame, f'{right_eye_pred_class.title()} ({right_eye_pred_acc}%)', (70, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.55, eye_class_colors[right_eye_pred_class], 2)\n",
    "            cv2.putText(frame, 'Sleep Attempts:', (15, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (45, 255, 45), 2)\n",
    "            cv2.putText(frame, f'{sleep_attempts}', (155, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, 'Yawn Attempts:', (15, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (45, 255, 45), 2)\n",
    "            cv2.putText(frame, f'{yawn_attempts}', (155, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 255), 2)\n",
    "\n",
    "        if sleep_counter > sleep_counter_thresh:\n",
    "            if sleep_counter % sleep_counter_thresh == 0:\n",
    "                if not last_alert_played_at:\n",
    "                    mixer.music.play()\n",
    "                    last_alert_played_at = time.time()\n",
    "                else:\n",
    "                    now = time.time()\n",
    "                    diff = int(round(now - last_alert_played_at, 1))\n",
    "                    if diff > alert_sound_len:\n",
    "                        mixer.music.play()\n",
    "                        last_alert_played_at = time.time()\n",
    "                sleep_attempts += 1\n",
    "            cv2.putText(frame, '[Critical Sleep Alert]', (220, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2)\n",
    "        elif yawn_attempts > prev_yawn_attempts:\n",
    "            sleep_mood_alert_countdown = sleep_mood_alert_countdown_thresh\n",
    "        if sleep_mood_alert_countdown and sleep_mood_alert_countdown > 0:\n",
    "            cv2.putText(frame, '[Sleepy Mood Alert]', (225, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 255), 2)\n",
    "            sleep_mood_alert_countdown -= 1\n",
    "\n",
    "        cv2.imshow('LIVE DROWSINESS DETECTION [SLEEPING + YAWNING]', frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2b9ed2f758ea7019c62ddc2c4686da189c449cf25e556e37851562caab2f41e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
